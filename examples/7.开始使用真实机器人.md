# 开始使用真实机器人

本教程将指导您如何设置并训练神经网络来自主控制真实机器人。

**您将学习：**
1. 如何订购和组装您的机器人。
2. 如何连接、配置和校准您的机器人。
3. 如何记录和可视化您的数据集。
4. 如何使用您的数据训练策略并准备进行评估。
5. 如何评估您的策略并可视化结果。

通过遵循这些步骤，您将能够复制诸如拾取乐高积木并将其放入垃圾桶等任务，并实现高成功率，如[此视频](https://x.com/RemiCadene/status/1814680760592572934)所示。

本教程专为经济实惠的[Koch v1.1](https://github.com/jess-moss/koch-v1-1)机器人设计，但也包含了一些额外信息，以便轻松适应各种类型的机器人，例如通过更改一些配置来适配[Aloha双手机器人](https://aloha-2.github.io)。Koch v1.1由一个领导臂和一个跟随臂组成，每个臂有6个电机。它可以与一个或多个摄像头配合使用，以记录场景，作为机器人的视觉传感器。

在数据收集阶段，您将通过移动领导臂来控制跟随臂。这个过程称为“遥操作”。该技术用于收集机器人轨迹。之后，您将训练一个神经网络来模仿这些轨迹，并部署该网络以使您的机器人能够自主操作。

如果您在教程的任何步骤中遇到问题，请随时在[Discord](https://discord.com/invite/s3KuuzsPFb)上寻求帮助，或者通过创建问题或拉取请求与我们迭代教程。谢谢！

## 1. 订购并组装您的Koch v1.1

按照[Koch v1.1 Github页面](https://github.com/jess-moss/koch-v1-1)上提供的采购和组装说明进行操作。这将指导您设置领导臂和跟随臂，如下图所示。

<div style="text-align:center;">
  <img src="../media/tutorial/koch_v1_1_leader_follower.webp?raw=true" alt="Koch v1.1领导臂和跟随臂" title="Koch v1.1领导臂和跟随臂" width="50%">
</div>

有关组装过程的视频教程，请参考[此视频教程](https://youtu.be/8nQIg9BwwTk)。

## 2. 配置电机、校准臂、遥操作您的Koch v1.1

首先，通过运行以下命令之一安装Koch v1.1等使用Dynamixel电机的机器人所需的额外依赖项（确保已安装gcc）。

使用`pip`：
```bash
pip install -e ".[dynamixel]"
```

或使用`poetry`：
```bash
poetry install --sync --extras "dynamixel"
```

/!\ 仅适用于Linux，ffmpeg和opencv目前需要通过conda安装。运行以下命令：
```bash
conda install -c conda-forge ffmpeg
pip uninstall opencv-python
conda install -c conda-forge "opencv>=4.10.0"
```

现在您可以将5V电源连接到领导臂（较小的那个）的电机总线，因为它的所有电机只需要5V。

然后将12V电源连接到跟随臂的电机总线。它有两个需要12V的电机，其余电机将通过电压转换器使用5V供电。

最后，通过USB将两个臂连接到您的计算机。请注意，USB不提供任何电源，两个臂都需要通过其相关电源供电才能被计算机检测到。

现在您可以首次配置电机，如下节所述。在接下来的部分中，您将通过运行一些Python代码或将其复制粘贴到Python文件中来了解我们的类和函数。

如果您已经首次配置了电机，可以通过直接运行遥操作脚本来简化流程（教程中会详细介绍）：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --control.type=teleoperate
```

它将自动：
1. 识别任何缺失的校准并启动校准程序。
2. 连接机器人并开始遥操作。

### a. 使用DynamixelMotorsBus控制电机

您可以使用[`DynamixelMotorsBus`](../lerobot/common/robot_devices/motors/dynamixel.py)与连接到相应USB总线的电机进行通信。该类利用Python [Dynamixel SDK](https://emanual.robotis.com/docs/en/software/dynamixel/dynamixel_sdk/sample_code/python_read_write_protocol_2_0/#python-read-write-protocol-20)来方便地从电机读取和写入数据。

**首次配置电机**

您需要依次拔下每个电机并运行命令来识别电机。电机会保存自己的识别信息，因此您只需执行一次此操作。首先拔下所有电机。

首先处理领导臂，因为它的所有电机都是同一类型。将领导臂上的第一个电机插入并运行此脚本将其ID设置为1。
```bash
python lerobot/scripts/configure_motor.py \
  --port /dev/tty.usbmodem58760432961 \
  --brand dynamixel \
  --model xl330-m288 \
  --baudrate 1000000 \
  --ID 1
```

然后拔下第一个电机并插入第二个电机，将其ID设置为2。
```bash
python lerobot/scripts/configure_motor.py \
  --port /dev/tty.usbmodem58760432961 \
  --brand dynamixel \
  --model xl330-m288 \
  --baudrate 1000000 \
  --ID 2
```

重复此过程，直到所有电机的ID设置为6。

跟随臂的过程几乎相同，但跟随臂有两种类型的电机。对于前两个电机，请确保将模型设置为`xl430-w250`。_重要提示：配置跟随电机需要插拔电源。确保您使用5V电源为XL330供电，使用12V电源为XL430供电！_

在所有电机正确配置后，您可以将它们全部以菊花链方式连接在一起，如原始视频所示。

**实例化DynamixelMotorsBus**

首先，为每个臂创建一个[`DynamixelMotorsBus`](../lerobot/common/robot_devices/motors/dynamixel.py)实例，使用它们对应的USB端口（例如`DynamixelMotorsBus(port="/dev/tty.usbmodem575E0031751"`）。

要找到每个臂的正确端口，请运行两次实用脚本：
```bash
python lerobot/scripts/find_motors_bus_port.py
```

识别领导臂端口的示例输出（例如，Mac上的`/dev/tty.usbmodem575E0031751`，或Linux上的`/dev/ttyACM0`）：
```
查找MotorBus的所有可用端口。
['/dev/tty.usbmodem575E0032081', '/dev/tty.usbmodem575E0031751']
拔下DynamixelMotorsBus的USB电缆，完成后按Enter。

[...断开领导臂并按下Enter...]

此DynamixelMotorsBus的端口是 /dev/tty.usbmodem575E0031751
重新连接USB电缆。
```

识别跟随臂端口的示例输出（例如，`/dev/tty.usbmodem575E0032081`，或Linux上的`/dev/ttyACM1`）：
```
查找MotorBus的所有可用端口。
['/dev/tty.usbmodem575E0032081', '/dev/tty.usbmodem575E0031751']
拔下DynamixelMotorsBus的USB电缆，完成后按Enter。

[...断开跟随臂并按下Enter...]

此DynamixelMotorsBus的端口是 /dev/tty.usbmodem575E0032081
重新连接USB电缆。
```

故障排除：在Linux上，您可能需要通过运行以下命令授予对USB端口的访问权限：
```bash
sudo chmod 666 /dev/tty.usbmodem575E0032081
sudo chmod 666 /dev/tty.usbmodem575E0031751
```

*列出和配置电机*

接下来，您需要列出每个臂的电机，包括它们的名称、索引和型号。最初，每个电机都被分配了工厂默认索引`1`。由于每个电机在连接到公共总线的链上时需要唯一的索引才能正常工作，因此您需要分配不同的索引。建议使用从`1`开始的升序索引（例如`1, 2, 3, 4, 5, 6`）。这些索引将在首次连接时保存到每个电机的持久内存中。

要为电机分配索引，请在交互式Python会话中运行此代码。将`port`值替换为您之前识别的值：
```python
from lerobot.common.robot_devices.motors.configs import DynamixelMotorsBusConfig
from lerobot.common.robot_devices.motors.dynamixel import DynamixelMotorsBus

leader_config = DynamixelMotorsBusConfig(
    port="/dev/tty.usbmodem575E0031751",
    motors={
        # 名称: (索引, 型号)
        "shoulder_pan": (1, "xl330-m077"),
        "shoulder_lift": (2, "xl330-m077"),
        "elbow_flex": (3, "xl330-m077"),
        "wrist_flex": (4, "xl330-m077"),
        "wrist_roll": (5, "xl330-m077"),
        "gripper": (6, "xl330-m077"),
    },
)

follower_config = DynamixelMotorsBusConfig(
    port="/dev/tty.usbmodem575E0032081",
    motors={
        # 名称: (索引, 型号)
        "shoulder_pan": (1, "xl430-w250"),
        "shoulder_lift": (2, "xl430-w250"),
        "elbow_flex": (3, "xl330-m288"),
        "wrist_flex": (4, "xl330-m288"),
        "wrist_roll": (5, "xl330-m288"),
        "gripper": (6, "xl330-m288"),
    },
)

leader_arm = DynamixelMotorsBus(leader_config)
follower_arm = DynamixelMotorsBus(follower_config)
```

重要提示：现在您已经有了端口，请更新[`KochRobotConfig`](../lerobot/common/robot_devices/robots/configs.py)。您会找到类似以下内容：
```python
@RobotConfig.register_subclass("koch")
@dataclass
class KochRobotConfig(ManipulatorRobotConfig):
    calibration_dir: str = ".cache/calibration/koch"
    # `max_relative_target`限制相对位置目标向量的大小以确保安全。
    # 将其设置为正标量以对所有电机使用相同的值，或设置为与跟随臂电机数量相同的列表。
    max_relative_target: int | None = None

    leader_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": DynamixelMotorsBusConfig(
                port="/dev/tty.usbmodem585A0085511", <-- 在此处更新
                motors={
                    # 名称: (索引, 型号)
                    "shoulder_pan": [1, "xl330-m077"],
                    "shoulder_lift": [2, "xl330-m077"],
                    "elbow_flex": [3, "xl330-m077"],
                    "wrist_flex": [4, "xl330-m077"],
                    "wrist_roll": [5, "xl330-m077"],
                    "gripper": [6, "xl330-m077"],
                },
            ),
        }
    )

    follower_arms: dict[str, MotorsBusConfig] = field(
        default_factory=lambda: {
            "main": DynamixelMotorsBusConfig(
                port="/dev/tty.usbmodem585A0076891", <-- 在此处更新
                motors={
                    # 名称: (索引, 型号)
                    "shoulder_pan": [1, "xl430-w250"],
                    "shoulder_lift": [2, "xl430-w250"],
                    "elbow_flex": [3, "xl330-m288"),
                    "wrist_flex": [4, "xl330-m288"),
                    "wrist_roll": [5, "xl330-m288"),
                    "gripper": [6, "xl330-m288"),
                },
            ),
        }
    )
```

**连接并配置电机**

在开始使用电机之前，您需要配置它们以确保正确的通信。当您首次连接电机时，[`DynamixelMotorsBus`](../lerobot/common/robot_devices/motors/dynamixel.py)会自动检测当前电机索引（工厂设置为`1`）与指定索引（例如`1, 2, 3, 4, 5, 6`）之间的不匹配。这将触发配置过程，要求您拔下电源线和电机，然后依次重新连接每个电机，从最靠近总线的电机开始。

有关配置过程的视频指南，请参考[配置过程的视频教程](https://youtu.be/U78QQ9wCdpY)。

要连接并配置领导臂，请在与教程前面相同的Python交互会话中运行以下代码：
```python
leader_arm.connect()
```

当您首次连接领导臂时，可能会看到类似以下的输出：
```
由于通信错误，读取失败，端口为/dev/tty.usbmodem575E0032081，组键为ID_shoulder_pan_shoulder_lift_elbow_flex_wrist_flex_wrist_roll_gripper：[TxRxResult] 没有状态包！

/!\ 检测到电机配置问题：
如果这是您首次使用这些电机，请按Enter配置电机...但在之前请确保所有电缆连接正确。如果发现问题，请在修改之前终止Python进程，拔下电源线以免损坏电机，重新正确接线，然后重新插入电源并重新启动脚本。

检测到的电机索引：{9600: [1]}

1. 拔下电源线
2. 插拔最少数量的电缆，仅连接第一个电机（['shoulder_pan']）。
3. 重新插入电源线
按Enter继续...

*遵循程序*

设置预期的电机索引：[1, 2, 3, 4, 5, 6]
```

领导臂配置完成后，通过运行以下代码重复跟随臂的配置过程：
```python
follower_arm.connect()
```

恭喜！两个臂现在都已正确配置并连接。未来您无需再次进行配置过程。

**故障排除**：

如果配置过程失败，您可能需要通过Dynamixel Wizard进行配置过程。

已知的故障模式：
- 在Ubuntu 22上调用`arm.connect()`时引发`OSError: 未找到电机，但预期有一个新电机。请验证电源线是否已插入并重试`。

步骤：
1. 访问 https://emanual.robotis.com/docs/en/software/dynamixel/dynamixel_wizard2/#connect-dynamixel。
2. 按照网页第3节中的软件安装说明进行操作。
3. 启动软件。
4. 在菜单中配置设备扫描选项，选择`工具` > `选项` > `扫描`。仅勾选协议2.0，选择感兴趣的USB端口标识符，选择所有波特率，将ID范围设置为`[0, 10]`。_虽然此步骤并非绝对必要，但它大大加快了扫描速度_。
5. 依次处理每个电机：
    - 断开驱动板的电源。
    - 仅将感兴趣的电机连接到驱动板，确保断开与其他电机的连接。
    - 重新连接驱动板的电源。
    - 从软件菜单中选择`设备` > `扫描`并运行扫描。应出现一个设备。
    - 如果设备旁边有星号（*），则表示固件确实已过时。从软件菜单中选择`工具` > `固件更新`。按照提示操作。
    - 主面板应包含设备的各种参数表（参考网页第5节）。选择带有`ID`的行，然后在右下角面板中设置所需的ID并点击`保存`。
    - 就像您对ID所做的那样，还将`波特率`设置为1 Mbps。
6. 检查一切是否正确：
   - 重新连接臂的最终配置并为其供电。
   - 扫描设备。应出现所有12个电机。
   - 依次选择电机并移动臂。检查右上角的图形指示器是否显示运动。

**使用DynamixelMotorsBus进行读写**

要熟悉`DynamixelMotorsBus`如何与电机通信，您可以从读取数据开始。将以下代码复制粘贴到相同的Python交互会话中：
```python
leader_pos = leader_arm.read("Present_Position")
follower_pos = follower_arm.read("Present_Position")
print(leader_pos)
print(follower_pos)
```

预期输出可能如下：
```
array([2054,  523, 3071, 1831, 3049, 2441], dtype=int32)
array([2003, 1601,   56, 2152, 3101, 2283], dtype=int32)
```

尝试将臂移动到不同位置并观察值的变化。

现在尝试通过复制粘贴以下代码来启用跟随臂的扭矩：
```python
from lerobot.common.robot_devices.motors.dynamixel import TorqueMode

follower_arm.write("Torque_Enable", TorqueMode.ENABLED.value)
```

启用扭矩后，跟随臂将锁定在其当前位置。请勿在扭矩启用时尝试手动移动臂，否则可能会损坏电机。

现在，为了更熟悉读写操作，让我们通过复制粘贴以下示例代码来编程移动臂：
```python
# 获取当前位置
position = follower_arm.read("Present_Position")

# 将第一个电机（shoulder_pan）的位置增加10步
position[0] += 10
follower_arm.write("Goal_Position", position)

# 将所有电机的位置减少30步
position -= 30
follower_arm.write("Goal_Position", position)

# 将夹爪增加30步
position[-1] += 30
follower_arm.write("Goal_Position", position[-1], "gripper")
```

当您完成操作后，可以尝试禁用扭矩，但请确保您扶住机器人以免其掉落：
```python
follower_arm.write("Torque_Enable", TorqueMode.DISABLED.value)
```

最后，断开臂的连接：
```python
leader_arm.disconnect()
follower_arm.disconnect()
```

或者，您可以拔下电源线，这将自动禁用扭矩并断开电机连接。

*/!\ 警告*：这些电机容易过热，尤其是在扭矩下或长时间插入电源时。使用后请拔下电源。

### b. 使用ManipulatorRobot遥操作您的Koch v1.1

**实例化ManipulatorRobot**

在遥操作机器人之前，您需要使用之前定义的`leader_config`和`follower_config`实例化[`ManipulatorRobot`](../lerobot/common/robot_devices/robots/manipulator.py)。

对于Koch v1.1机器人，我们只有一个领导臂，因此我们将其称为`"main"`并将其定义为`leader_arms={"main": leader_config}`。我们对跟随臂也做同样的操作。对于其他机器人（如Aloha），可能有两对领导臂和跟随臂，您可以这样定义它们：`leader_arms={"left": left_leader_config, "right": right_leader_config},`。跟随臂也是如此。

运行以下代码以实例化您的操作机器人：
```python
from lerobot.common.robot_devices.robots.configs import KochRobotConfig
from lerobot.common.robot_devices.robots.manipulator import ManipulatorRobot

robot_config = KochRobotConfig(
    leader_arms={"main": leader_config},
    follower_arms={"main": follower_config},
    cameras={},  # 我们现在不使用任何摄像头
)
robot = ManipulatorRobot(robot_config)
```

`KochRobotConfig`用于设置相关设置和校准过程。例如，我们激活Koch v1.1领导臂夹爪的扭矩并将其定位在40度角以用作触发器。

对于[Aloha双手机器人](https://aloha-2.github.io)，我们将使用`AlohaRobotConfig`来设置不同的设置，例如阴影关节（肩部、肘部）的辅助ID。特定于Aloha，LeRobot附带存储在`.cache/calibration/aloha_default`中的默认校准文件。假设电机已正确组装，Aloha无需手动校准步骤。

**校准并连接ManipulatorRobot**

接下来，您需要校准您的Koch机器人，以确保领导臂和跟随臂在相同物理位置时具有相同的位置值。此校准至关重要，因为它允许在一个Koch机器人上训练的神经网络在另一个机器人上工作。

当您首次连接机器人时，[`ManipulatorRobot`](../lerobot/common/robot_devices/robots/manipulator.py)将检测校准文件是否缺失并触发校准过程。在此过程中，您将被引导将每个臂移动到三个不同的位置。

以下是您将跟随臂移动到的位置：

| 1. 零位                                                      | 2. 旋转位置                                                  | 3. 休息位置                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="../media/koch/follower_zero.webp?raw=true" alt="Koch v1.1跟随臂零位" title="Koch v1.1跟随臂零位" style="width:100%;"> | <img src="../media/koch/follower_rotated.webp?raw=true" alt="Koch v1.1跟随臂旋转位置" title="Koch v1.1跟随臂旋转位置" style="width:100%;"> | <img src="../media/koch/follower_rest.webp?raw=true" alt="Koch v1.1跟随臂休息位置" title="Koch v1.1跟随臂休息位置" style="width:100%;"> |

以下是领导臂的对应位置：

| 1. 零位                                                      | 2. 旋转位置                                                  | 3. 休息位置                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="../media/koch/leader_zero.webp?raw=true" alt="Koch v1.1领导臂零位" title="Koch v1.1领导臂零位" style="width:100%;"> | <img src="../media/koch/leader_rotated.webp?raw=true" alt="Koch v1.1领导臂旋转位置" title="Koch v1.1领导臂旋转位置" style="width:100%;"> | <img src="../media/koch/leader_rest.webp?raw=true" alt="Koch v1.1领导臂休息位置" title="Koch v1.1领导臂休息位置" style="width:100%;"> |

您可以观看[校准过程的视频教程](https://youtu.be/8drnU9uRY24)以获取更多详细信息。

在校准过程中，我们计算自首次使用以来电机所做的完整360度旋转次数。这就是为什么我们要求您移动到此任意的“零”位置。我们实际上并不“设置”零位，因此您无需精确。在计算这些“偏移量”以将电机值围绕0进行调整后，我们需要评估每个电机的旋转方向，这可能会有所不同。这就是为什么我们要求您将所有电机旋转到大约90度，以测量值是负向还是正向变化。

最后，休息位置确保校准后跟随臂和领导臂大致对齐，防止在开始遥操作时突然移动损坏电机。

重要的是，一旦校准完成，所有Koch机器人在命令下都将移动到相同的位置（例如零位和旋转位置）。

运行以下代码以校准并连接您的机器人：
```python
robot.connect()
```

输出将如下所示：
```
连接主跟随臂
连接主领导臂

缺少校准文件 '.cache/calibration/koch/main_follower.json'
正在校准koch主跟随臂...
将臂移动到零位
[...]
将臂移动到旋转位置
[...]
将臂移动到休息位置
[...]
校准完成！保存校准文件 '.cache/calibration/koch/main_follower.json'

缺少校准文件 '.cache/calibration/koch/main_leader.json'
正在校准koch主领导臂...
将臂移动到零位
[...]
将臂移动到旋转位置
[...]
将臂移动到休息位置
[...]
校准完成！保存校准文件 '.cache/calibration/koch/main_leader.json'
```

# 校准验证

在校准完成后，您可以检查领导臂和跟随臂的位置，以确保它们匹配。如果校准成功，位置应该非常相似。

运行此代码以获取以度为单位的位置：
```python
leader_pos = robot.leader_arms["main"].read("Present_Position")
follower_pos = robot.follower_arms["main"].read("Present_Position")

print(leader_pos)
print(follower_pos)
```

示例输出：
```
array([-0.43945312, 133.94531, 179.82422, -18.984375, -1.9335938, 34.541016], dtype=float32)
array([-0.58723712, 131.72314, 174.98743, -16.872612, 0.786213, 35.271973], dtype=float32)
```

这些值以度为单位，使它们更易于解释和调试。校准过程中使用的零位应该大致对应于每个电机的 0 度，旋转位置应该大致对应于每个电机的 90 度。

## 远程操作您的 Koch v1.1

您可以通过从领导手臂读取位置，并将其作为目标位置发送给跟随手臂，轻松远程操作机器人。

要以约 200Hz 的频率远程操作您的机器人 30 秒，请运行以下代码：
```python
import tqdm
seconds = 30
frequency = 200
for _ in tqdm.tqdm(range(seconds * frequency)):
    leader_pos = robot.leader_arms["main"].read("Present_Position")
    robot.follower_arms["main"].write("Goal_Position", leader_pos)
```

## 使用 `teleop_step` 进行远程操作

另外，您可以使用 [`ManipulatorRobot`](../lerobot/common/robot_devices/robots/manipulator.py) 中的 `teleop_step` 方法来远程操作机器人。

运行以下代码进行远程操作：
```python
for _ in tqdm.tqdm(range(seconds * frequency)):
    robot.teleop_step()
```

## 在远程操作期间记录数据

远程操作对于记录数据特别有用。您可以使用 `teleop_step(record_data=True)` 来返回跟随臂的位置作为 `"observation.state"`，领导臂的位置作为 `"action"`。此功能还将 numpy 数组转换为 PyTorch 张量。如果您正在使用具有两个领导臂和两个跟随臂的机器人（如 Aloha），则位置将被连接在一起。

运行以下代码，以查看缓慢移动领导臂如何影响观察和动作：
```python
leader_pos = robot.leader_arms["main"].read("Present_Position")
follower_pos = robot.follower_arms["main"].read("Present_Position")
observation, action = robot.teleop_step(record_data=True)

print(follower_pos)
print(observation)
print(leader_pos)
print(action)
```

预期输出：
```
array([7.8223, 131.1328, 165.5859, -23.4668, -0.9668, 32.4316], dtype=float32)
{'observation.state': tensor([7.8223, 131.1328, 165.5859, -23.4668, -0.9668, 32.4316])}
array([3.4277, 134.1211, 179.8242, -18.5449, -1.5820, 34.7168], dtype=float32)
{'action': tensor([3.4277, 134.1211, 179.8242, -18.5449, -1.5820, 34.7168])}
```

## 异步帧记录

此外，`teleop_step` 还可以从多个相机异步记录帧，并将它们包含在观察字典中，作为 `"observation.images.CAMERA_NAME"`。这个功能将在下一节中详细介绍。

## 断开连接机器人

完成后，请确保通过运行以下命令来断开机器人：
```python
robot.disconnect()
```

或者，您可以拔掉电源线，这也会禁用扭矩。

/!\ 警告：这些电机容易过热，尤其在施加扭矩或长时间插入状态下。使用结束后请拔掉电源。

## c. 使用 OpenCVCamera 添加相机

**（可选）在 Linux 上使用手机作为相机**

如果您希望在 Linux 上使用手机作为相机，请按照以下步骤设置虚拟相机。

1. *安装 `v4l2loopback-dkms` 和 `v4l-utils`*。这些软件包是创建虚拟相机设备（`v4l2loopback`）和使用 `v4l2-ctl` 工具验证设置所必需的。使用以下命令安装：
```bash
sudo apt install v4l2loopback-dkms v4l-utils
```
2. *在手机上安装 [DroidCam](https://droidcam.app)*。此应用程序在 iOS 和 Android 上均可用。
3. *安装 [OBS Studio](https://obsproject.com)*。此软件将帮助您管理相机输入。使用 [Flatpak](https://flatpak.org) 安装它：
```bash
flatpak install flathub com.obsproject.Studio
```
4. *安装 DroidCam OBS 插件*。此插件将 DroidCam 与 OBS Studio 集成。使用以下命令安装：
```bash
flatpak install flathub com.obsproject.Studio.Plugin.DroidCam
```
5. *启动 OBS Studio*。使用以下命令启动：
```bash
flatpak run com.obsproject.Studio
```
6. *将手机添加为源*。按照 [这里](https://droidcam.app/obs/usage) 的说明进行操作。请确保将分辨率设置为 `640x480`。
7. *调整分辨率设置*。在 OBS Studio 中，转到 `文件 > 设置 > 视频`。手动将 `基础（画布）分辨率` 和 `输出（缩放）分辨率` 更改为 `640x480`。
8. *启用虚拟相机*。在 OBS Studio 中，按照 [这里](https://obsproject.com/kb/virtual-camera-guide) 的说明进行操作。
9. *验证虚拟相机设置*。使用 `v4l2-ctl` 列出设备：
```bash
v4l2-ctl --list-devices
```
您应该会看到类似以下条目：
```
VirtualCam (platform:v4l2loopback-000):
/dev/video1
```
10. *检查相机分辨率*。使用 `v4l2-ctl` 确保虚拟相机输出分辨率为 `640x480`。将 `/dev/video1` 更改为您在 `v4l2-ctl --list-devices` 输出中找到的虚拟相机端口。
```bash
v4l2-ctl -d /dev/video1 --get-fmt-video
```
您应该会看到类似以下条目的输出：
```
>>> Format Video Capture:
>>>	Width/Height      : 640/480
>>>	Pixel Format      : 'YUYV' (YUYV 4:2:2)
```

故障排除：如果分辨率不正确，您需要删除虚拟相机端口并重试，因为它无法更改。

如果一切设置正确，您可以继续教程的其余部分。

**（可选）在 macOS 上使用 iPhone 作为相机**

要在 macOS 上使用 iPhone 作为相机，启用连续性相机功能：
- 确保您的 Mac 运行的是 macOS 13 或更高版本，您的 iPhone 运行的是 iOS 16 或更高版本。
- 在两台设备上使用相同的 Apple ID 登录。
- 用 USB 线连接设备或打开 Wi-Fi 和蓝牙进行无线连接。

有关更多详细信息，请访问 [Apple 支持](https://support.apple.com/en-gb/guide/mac-help/mchl77879b8a/mac)。

您的 iPhone 应在运行下一节的相机设置脚本时自动检测到。

## 实例化 OpenCVCamera

[`OpenCVCamera`](../lerobot/common/robot_devices/cameras/opencv.py) 类允许您使用 [`opencv2`](https://docs.opencv.org) 库有效录制来自大多数相机的帧。有关兼容性的更多详细信息，请参见 [OpenCV 视频 I/O 概述](https://docs.opencv.org/4.x/d0/da7/videoio_overview.html)。

要实例化 [`OpenCVCamera`](../lerobot/common/robot_devices/cameras/opencv.py)，您需要一个相机索引（例如 `OpenCVCamera(camera_index=0)`）。当您只有一个相机（例如笔记本电脑的网络摄像头）时，相机索引通常为 `0`，但它可能会有所不同，并且相机索引在重启计算机或重新插入相机时可能会变化。这种行为取决于您的操作系统。

要查找相机索引，运行以下实用脚本，该脚本将保存每个检测到的相机的几帧：
```bash
python lerobot/common/robot_devices/cameras/opencv.py \
    --images-dir outputs/images_from_opencv_cameras
```

输出结果如下，如果您连接了两台相机：
```
Mac or Windows detected. Finding available camera indices through scanning all indices from 0 to 60
[...]
Camera found at index 0
Camera found at index 1
[...]
Connecting cameras
OpenCVCamera(0, fps=30.0, width=1920.0, height=1080.0, color_mode=rgb)
OpenCVCamera(1, fps=24.0, width=1920.0, height=1080.0, color_mode=rgb)
Saving images to outputs/images_from_opencv_cameras
Frame: 0000	Latency (ms): 39.52
[...]
Frame: 0046	Latency (ms): 40.07
Images have been saved to outputs/images_from_opencv_cameras
```

检查保存的图像，以确定哪个相机索引对应于哪个物理相机（例如 `0` 对应 `camera_00` 或 `1` 对应 `camera_01`）：
```
camera_00_frame_000000.png
[...]
camera_00_frame_000047.png
camera_01_frame_000000.png
[...]
camera_01_frame_000047.png
```

注意：某些相机可能需要几秒钟才能预热，第一帧可能是黑色或绿色。

最后，运行以下代码来实例化并连接您的相机：
```python
from lerobot.common.robot_devices.cameras.configs import OpenCVCameraConfig
from lerobot.common.robot_devices.cameras.opencv import OpenCVCamera

camera_config = OpenCVCameraConfig(camera_index=0)
camera = OpenCVCamera(camera_config)
camera.connect()
color_image = camera.read()

print(color_image.shape)
print(color_image.dtype)
```

对于 MacBookPro 上的笔记本电脑相机，预期输出如下：
```
(1080, 1920, 3)
uint8
```

或者，如果您按照我们的教程设置虚拟相机，输出如下：
```
(480, 640, 3)
uint8
```

使用某些相机，您还可以在实例化时指定额外参数，如帧速率、分辨率和颜色模式。例如：
```python
camera_config = OpenCVCameraConfig(camera_index=0, fps=30, width=640, height=480)
```

如果提供的参数与相机不兼容，将引发异常。

## 断开连接相机

使用完相机后，通过运行以下命令断开连接：
```python
camera.disconnect()
```

## 实例化带有相机的机器人

此外，您可以将机器人设置为与相机一起使用。

使用适当的相机名称和配置修改以下 Python 代码：
```python
robot = ManipulatorRobot(
    leader_arms={"main": leader_arm},
    follower_arms={"main": follower_arm},
    calibration_dir=".cache/calibration/koch",
    cameras={
        "laptop": OpenCVCameraConfig(0, fps=30, width=640, height=480),
        "phone": OpenCVCameraConfig(1, fps=30, width=640, height=480),
    },
)
robot.connect()
```

因此，`teleop_step(record_data=True)` 将为每个相机返回一个帧，遵循 PyTorch 的“通道优先”约定，但我们将图像保持为 `uint8`，并且像素范围为 [0,255]，以便轻松保存它们。

用您的相机名称修改此代码并运行：
```python
observation, action = robot.teleop_step(record_data=True)
print(observation["observation.images.laptop"].shape)
print(observation["observation.images.phone"].shape)
print(observation["observation.images.laptop"].min().item())
print(observation["observation.images.laptop"].max().item())
```

输出应如下所示：
```
torch.Size([3, 480, 640])
torch.Size([3, 480, 640])
0
255
```

## d. 使用 `control_robot.py` 和我们的 `teleoperate` 功能

您可以使用 [`lerobot/scripts/control_robot.py`](../lerobot/scripts/control_robot.py) 提供机器人配置的命令行来实例化您的机器人，并以各种模式控制您的机器人，具体如下所述。

尝试运行以下代码以远程操作您的机器人（如果您没有相机，请继续阅读）：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --control.type=teleoperate
```

您将看到很多类似以下内容的行：
```
INFO 2024-08-10 11:15:03 ol_robot.py:209 dt: 5.12 (195.1hz) dtRlead: 4.93 (203.0hz) dtRfoll: 0.19 (5239.0hz)
```

它包含：
- `2024-08-10 11:15:03`，这是调用打印函数的日期和时间。
- `ol_robot.py:209`，这是调用打印函数的文件名末尾和行号（`lerobot/scripts/control_robot.py` 的第 `209` 行）。
- `dt: 5.12 (195.1hz)`，这是在上一次调用 `robot.teleop_step()` 和当前调用之间消耗的毫秒数，及其对应的频率（5.12 毫秒等于 195.1 Hz）；注意，您可以通过添加参数来控制最大频率，如 `--fps 30`。
- `dtRlead: 4.93 (203.0hz)`，这是读取领导臂位置所需的毫秒数。
- `dtWfoll: 0.19 (5239.0hz)`，这是设置跟随臂新目标位置所需的毫秒数；请注意，写入是异步进行的，因此所需的时间少于读取的时间。

重要的是：如果您没有任何相机，您可以使用此 [draccus](https://github.com/dlwh/draccus) 语法动态删除它们 `--robot.cameras='{}'`：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --robot.cameras='{}' \
  --control.type=teleoperate
```

建议您在命令变得太长时创建新的 YAML 文件。

## 3. 记录数据集并可视化

使用您之前学到的知识，您现在可以轻松记录一个状态和动作的数据集，以供一集使用。您可以使用 `busy_wait` 来控制远程操作的速度，并以固定的 `fps`（帧每秒）记录。

尝试运行以下代码以每秒 60 帧的速度录制 30 秒：
```python
import time
from lerobot.scripts.control_robot import busy_wait

record_time_s = 30
fps = 60

states = []
actions = []
for _ in range(record_time_s * fps):
    start_time = time.perf_counter()
    observation, action = robot.teleop_step(record_data=True)

    states.append(observation["observation.state"])
    actions.append(action["action"])

    dt_s = time.perf_counter() - start_time
    busy_wait(1 / fps - dt_s)

# 请注意，观察和动作保留在内存中，但是
# 您还可以使用 pickle/hdf5 或
# 我们优化的格式 `LeRobotDataset` 将它们存储在磁盘上。有关更多信息，请参见下一节。
```

重要的是，许多实用程序仍然缺失。例如，如果您有相机，则需要将图像保存到磁盘，以防止超出 RAM，并且使用线程这样做，以免减慢与机器人之间的通信。此外，您还需要以优化的格式（如 [`LeRobotDataset`](../lerobot/common/datasets/lerobot_dataset.py)）存储数据，以便于训练和网络共享。有关更多信息，请参见下一节。

## a. 使用 `record` 函数

您可以使用 [`lerobot/scripts/control_robot.py`](../lerobot/scripts/control_robot.py) 中的 `record` 函数有效地记录数据。它涵盖了许多记录实用程序：
1. 相机的帧在线程中保存到磁盘，并在每个会话记录结束时编码为视频。
2. 来自相机的实时视频流显示在窗口中，以便您验证它们。
3. 数据以 [`LeRobotDataset`](../lerobot/common/datasets/lerobot_dataset.py) 格式存储，并推送到您的 Hugging Face 页面（除非提供 `--control.push_to_hub=false`）。
4. 在记录过程中执行检查点，因此如果出现问题，您可以通过再次运行相同的命令并添加 `--control.resume=true` 来恢复记录。如果您的数据集未上传至 Hugging Face 主页，您可能需要添加 `--control.local_files_only=true`，此外，您需要在开始重新录制之前手动删除数据集目录。
5. 使用命令行参数设置数据记录的流：
   - `--control.warmup_time_s=10` 定义开始数据收集之前的秒数。它允许机器人设备预热并同步（默认 10 秒）。
   - `--control.episode_time_s=60` 定义每集的数据录制时间（默认 60 秒）。
   - `--control.reset_time_s=60` 定义每个集之后重置环境的秒数（默认 60 秒）。
   - `--control.num_episodes=50` 定义要记录的集数（默认 50）。
6. 在数据记录期间，通过键盘控制流动：
   - 在任何时间按右箭头 `->` 在剧集录制期间提前停止并转到重置。同样在重置期间，提前停止并转到下一次剧集录制。
   - 在任何时间按左箭头 `<-` 在剧集录制或重置期间提前停止，取消当前剧集并重新录制它。
   - 在任何时间按下 Escape `ESC`，提前结束录制会话并直接转到视频编码和数据集上传。
7. 与 `teleoperate` 类似，您也可以通过命令行覆盖任何内容。

在尝试 `record` 之前，如果要将数据集推送到中心，请确保您已使用写入访问令牌登录，该令牌可以从 [Hugging Face 设置](https://huggingface.co/settings/tokens) 中生成：
```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```
此外，将您的 Hugging Face 存储库名称存储在变量中（例如 `cadene` 或 `lerobot`）。例如，运行以下命令以将您的 Hugging Face 用户名用作存储库：
```bash
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```
如果您不想推送到中心，请使用 `--control.push_to_hub=false`。

现在运行以下命令以记录 2 次剧集：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --control.type=record \
  --control.single_task="抓取一个瓶子并把它放入箱子。" \
  --control.fps=30 \
  --control.repo_id=${HF_USER}/koch_test \
  --control.tags='["tutorial"]' \
  --control.warmup_time_s=5 \
  --control.episode_time_s=30 \
  --control.reset_time_s=30 \
  --control.num_episodes=10 \
  --control.push_to_hub=true
```

这将在本地写入您的数据集到 `~/.cache/huggingface/lerobot/{repo-id}`（例如 `data/cadene/koch_test`），并将其推送到中心，网址为 `https://huggingface.co/datasets/{HF_USER}/{repo-id}`。您的数据集将自动标记为 `LeRobot`，以便社区轻松找到它，您还可以添加自定义标签（在这种情况下为 `tutorial`）。

您将看到很多类似以下内容的行：
```
INFO 2024-08-10 15:02:58 ol_robot.py:219 dt:33.34 (30.0hz) dtRlead: 5.06 (197.5hz) dtWfoll: 0.25 (3963.7hz) dtRfoll: 6.22 (160.7hz) dtRlaptop: 32.57 (30.7hz) dtRphone: 33.84 (29.5hz)
```

它包含：
- `2024-08-10 15:02:58`，这是调用打印函数的日期和时间。
- `ol_robot.py:219`，这是调用打印函数的文件名末尾和行号（`lerobot/scripts/control_robot.py` 的第 `219` 行）。
- `dt:33.34 (30.0hz)`，这是在上一次调用 `robot.teleop_step(record_data=True)` 和当前调用之间消耗的毫秒数，及其对应的频率（33.34 毫秒等于 30.0 Hz）；注意，我们使用 `--fps 30` 所以我们期望 30.0 Hz；当某个步骤消耗更多时间时，该行会以黄色显示。
- `dtRlead: 5.06 (197.5hz)`，这是读取领导臂当前的位置所需的时间。
- `dtWfoll: 0.25 (3963.7hz)`，这是在异步线程中捕获图像所需的时间。

故障排除：
- 在 Linux 上，如果您在使用相机时遇到挂起问题，请卸载 opencv 并使用 conda 重新安装：
```bash
pip uninstall opencv-python
conda install -c conda-forge opencv=4.10.0
```
- 在 Linux 上，如果您在 `ffmpeg: unknown encoder libsvtav1` 视频编码期间遇到任何问题，您可以：
  - 通过运行 `conda install -c conda-forge ffmpeg`（应该与 `libsvtav1` 编译）来进行安装，
  - 或安装 [Homebrew](https://brew.sh)，然后运行 `brew install ffmpeg`（应该与 `libsvtav1` 编译），
  - 或安装 [ffmpeg 构建依赖](https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu#GettheDependencies) 并 [使用 libsvtav1 从源头编译 ffmpeg](https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu#libsvtav1)，
  - 确保您使用的 ffmpeg 二进制文件与您的安装相对应，使用 `which ffmpeg` 确认。
- 在 Linux 上，如果左箭头和右箭头键以及 Escape 键在数据录制时没有任何效果，请确保您已经设置了 `$DISPLAY` 环境变量。参见 [pynput 限制](https://pynput.readthedocs.io/en/latest/limitations.html#linux)。

在数据录制结束时，您的数据集将被上传到您的 Hugging Face 页面（例如 `https://huggingface.co/datasets/cadene/koch_test`），可以通过运行以下命令获取：
```bash
echo https://huggingface.co/datasets/${HF_USER}/koch_test
```

## b. 录制数据集的建议

一旦您熟悉了数据录制，就可以开始创建一个更大的数据集用于训练。一个良好的开始任务是抓取一个物体并将其放在一个箱子里。我们建议录制至少 50 个剧集，每个位置 10 个剧集。保持相机固定，并在整个录制过程中保持一致的抓取行为。

在随后几节中，您将训练您的神经网络。在实现可靠的抓取性能后，您可以开始在数据采集中引入更多变体，如附加抓取位置、不同的抓取技术和改变相机位置。

尽量避免过快地增加太多变异，因为这可能会影响您的结果。

在接下来的几个月中，我们计划发布一个用于机器人技术的基础模型。我们预计微调该模型将增强模型的泛化能力，降低数据采集中的严格一致性需求。

## c. 可视化所有剧集

您可以通过运行以下命令可视化数据集：
```bash
python lerobot/scripts/visualize_dataset_html.py \
  --repo-id ${HF_USER}/koch_test
```

注意：如果您的数据集未上传到 Hugging Face 中心，您可能需要添加 `--local-files-only 1`。

这将启动一个本地网络服务器，如下所示：
<div style="text-align:center;">
  <img src="../media/tutorial/visualize_dataset_html.webp?raw=true" alt="Koch v1.1 领导和跟随臂" title="Koch v1.1 领导和跟随臂" width="100%">
</div>

## d. 使用 `replay` 函数在您的机器人上重播剧集

[`lerobot/scripts/control_robot.py`](../lerobot/scripts/control_robot.py) 的一个有用功能是 `replay` 函数，它允许您重播所记录的任何剧集，或来自任何数据集的剧集。此功能帮助您测试机器人动作的可重复性，并评估相同模型的机器人间的可迁移性。

要重播您刚录制的数据集的第一集，请运行以下命令：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --control.type=replay \
  --control.fps=30 \
  --control.repo_id=${HF_USER}/koch_test \
  --control.episode=0
```

注意：如果您的数据集未上传到 Hugging Face 中心，您可能需要添加 `--control.local_files_only=true`。

您的机器人应重复移动，类似于您记录的那样。例如，请查看 [这个视频](https://x.com/RemiCadene/status/1793654950905680090)，其中我们在 Trossen Robotics 的 [Aloha 机器人](https://www.trossenrobotics.com) 上使用 `replay` 函数。

## 4. 在您的数据上训练策略

### a. 使用 `train` 脚本

要训练控制机器人的策略，请使用 [`python lerobot/scripts/train.py`](../lerobot/scripts/train.py) 脚本。需要一些参数。以下是示例命令：
```bash
python lerobot/scripts/train.py \
  --dataset.repo_id=${HF_USER}/koch_test \
  --policy.type=act \
  --output_dir=outputs/train/act_koch_test \
  --job_name=act_koch_test \
  --device=cuda \
  --wandb.enable=true
```

注意：如果您的数据集未上传到 Hugging Face 中心，您可能需要添加 `--dataset.local_files_only=true`。

让我们解释一下：
1. 我们使用 `--dataset.repo_id=${HF_USER}/koch_test` 提供数据集作为参数。
2. 我们使用 `policy.type=act` 提供策略。这加载 [`configuration_act.py`](../lerobot/common/policies/act/configuration_act.py) 中的配置。重要的是，该策略将自动适应您机器人的电机状态、电机动作和相机的数量（例如 `laptop` 和 `phone`），这些信息已存储在您的数据集中。
3. 我们提供 `device=cuda`，因为我们在 Nvidia GPU 上进行训练，但您可以使用 `device=mps` 在 Apple 硬件上进行训练。
4. 我们提供 `wandb.enable=true`，使用 [Weights 和 Biases](https://docs.wandb.ai/quickstart) 来可视化训练图表。这是可选的，但如果您使用它，请确保通过运行 `wandb login` 进行登录。

有关 `train` 脚本的更多信息，请参阅之前的教程：[`examples/4_train_policy_with_script.md`](../examples/4_train_policy_with_script.md)

### b. （可选）将策略检查点上传到中心

训练完成后，使用以下命令上传最新的检查点：
```bash
huggingface-cli upload ${HF_USER}/act_koch_test \
  outputs/train/act_koch_test/checkpoints/last/pretrained_model
```

您还可以使用以下命令上传中间检查点：
```bash
CKPT=010000
huggingface-cli upload ${HF_USER}/act_koch_test_${CKPT} \
  outputs/train/act_koch_test/checkpoints/${CKPT}/pretrained_model
```

## 5. 评估您的策略

现在您有了策略检查点，可以使用 [`ManipulatorRobot`](../lerobot/common/robot_devices/robots/manipulator.py) 和策略轻松控制您的机器人。

尝试运行以下代码，在 60 秒内以 30 fps 进行推断：
```python
from lerobot.common.policies.act.modeling_act import ACTPolicy

inference_time_s = 60
fps = 30
device = "cuda"  # TODO: 在 Mac 上，使用 "mps" 或 "cpu"

ckpt_path = "outputs/train/act_koch_test/checkpoints/last/pretrained_model"
policy = ACTPolicy.from_pretrained(ckpt_path)
policy.to(device)

for _ in range(inference_time_s * fps):
    start_time = time.perf_counter()

    # 读取跟随臂状态并访问相机的帧
    observation = robot.capture_observation()

    # 转换为 pytorch 格式：通道优先，浮点数 [0,1]，带有批量维度
    for name in observation:
        if "image" in name:
            observation[name] = observation[name].type(torch.float32) / 255
            observation[name] = observation[name].permute(2, 0, 1).contiguous()
        observation[name] = observation[name].unsqueeze(0)
        observation[name] = observation[name].to(device)

    # 根据当前观察计算下一个动作
    action = policy.select_action(observation)
    # 去掉批量维度
    action = action.squeeze(0)
    # 移动到 CPU，如果还未移动
    action = action.to("cpu")
    # 告诉机器人移动
    robot.send_action(action)

    dt_s = time.perf_counter() - start_time
    busy_wait(1 / fps - dt_s)
```

### a. 使用我们的 `record` 函数

理想情况下，当使用神经网络控制机器人时，您会希望记录评估剧集，并能够在以后可视化它们，甚至像在强化学习中一样进行训练。这基本上对应于录制一个新的数据集，但由神经网络提供动作，而不是通过远程操作提供。

为此，您可以使用来自 [`lerobot/scripts/control_robot.py`](../lerobot/scripts/control_robot.py) 的 `record` 函数，但使用政策检查点作为输入。例如，运行此命令录制 10 个评估剧集：
```bash
python lerobot/scripts/control_robot.py \
  --robot.type=koch \
  --control.type=record \
  --control.fps=30 \
  --control.repo_id=${HF_USER}/eval_act_koch_test \
  --control.tags='["tutorial"]' \
  --control.warmup_time_s=5 \
  --control.episode_time_s=30 \
  --control.reset_time_s=30 \
  --control.num_episodes=10 \
  --control.push_to_hub=true \
  --control.policy.path=outputs/train/act_koch_test/checkpoints/last/pretrained_model
```

如您所见，它与之前录制训练数据集的命令几乎相同。只有两件事发生了变化：
1. 另一个参数 `--control.policy.path` 表示策略检查点的路径（例如 `outputs/train/eval_koch_test/checkpoints/last/pretrained_model`）。您也可以使用仓库模型，如果您已将模型检查点上传到中心（例如 `${HF_USER}/act_koch_test`）。
2. 数据集的名称以 `eval` 开头，以反映您正在进行推断（例如 `${HF_USER}/eval_act_koch_test`）。

### b. 随后可视化评估

然后，您可以通过运行与之前相同的命令，但将新的推断数据集作为参数可视化：
```bash
python lerobot/scripts/visualize_dataset.py \
  --repo-id ${HF_USER}/eval_act_koch_test
```

## 6. 下一步

加入我们的 [Discord](https://discord.com/invite/s3KuuzsPFb)，共同协作进行数据收集，并帮助我们训练一个完全开源的机器人基础模型！